import express from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import morgan from 'morgan';
import fetch from 'node-fetch';
import { v4 as uuidv4 } from 'uuid';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// Load .env from backend directory
dotenv.config({ path: join(__dirname, '.env') });

const app = express();
const port = process.env.PORT || 4000;
const clientOrigin = process.env.CLIENT_ORIGIN || 'http://localhost:5173';
// Allow Azure frontend domain
const allowedOrigins = [
  clientOrigin,
  'https://hongkongtutor-f4b5gzd3fbfdhxdw.eastasia-01.azurewebsites.net'
];
const appVersion = process.env.APP_VERSION || '0.1.0-prototype';
const ttsProvider = (process.env.TTS_PROVIDER || 'mock').toLowerCase();
const azureTtsKey = process.env.AZURE_SPEECH_KEY;
const azureTtsRegion = process.env.AZURE_SPEECH_REGION;
const azureVoice = process.env.AZURE_TTS_VOICE || 'zh-HK-HiuMaanNeural';
const azureRate = process.env.AZURE_TTS_RATE || '0%';
const azurePitch = process.env.AZURE_TTS_PITCH || '0%';
const hkbuApiKey = process.env.HKBU_API_KEY;
const hkbuBaseUrl = process.env.HKBU_BASE_URL || 'https://genai.hkbu.edu.hk/api/v0/rest';
const hkbuModel = process.env.HKBU_MODEL || 'gpt-5';
const hkbuApiVersion = process.env.HKBU_API_VERSION || '2024-12-01-preview';

app.disable('x-powered-by');
app.use(morgan(process.env.LOG_FORMAT || 'dev'));

app.use(cors({ 
  origin: (origin, callback) => {
    if (!origin || allowedOrigins.includes(origin)) {
      callback(null, true);
    } else {
      callback(new Error('Not allowed by CORS'));
    }
  },
  credentials: true 
}));
app.use(express.json({ limit: '2mb' }));
app.use((req, res, next) => {
  req.startTime = Date.now();
  next();
});
app.use((req, res, next) => {
  req.startTime = Date.now();
  next();
});

// In-memory conversation store; in production use a DB or cache.
const conversations = new Map();

const scenarios = [
  'è‡ªç”±å°è©± (Free Conversation)',
  'é¤å»³é»žé¤ (At the Restaurant)',
  'èªè­˜æ–°æœ‹å‹ (Meeting New People)',
  'åŽ»é¦™æ¸¯æ—…è¡Œ (Traveling in Hong Kong)',
  'è³¼ç‰©é–’èŠ (Shopping Small Talk)',
  'å·¥ä½œå¯’æš„ (Workplace Small Talk)'
];

// Very small Cantonese prompt seeds for mock responses.
const promptSeeds = [
  'ä½ è¬›å¾—å¥½æµåˆ©ï¼Œç¹¼çºŒåˆ†äº«å¤šå•²ï¼',
  'å¯ä»¥å†è¬›è©³ç´°å•²å—Žï¼Ÿ',
  'æ˜Žç™½ï¼Œä½ ä»²æœ‰å’©æƒ³æ³•ï¼Ÿ',
  'ä¸å¦‚è¬›ä¸‹ä½ å˜…æ—¥å¸¸ï¼Ÿ',
  'å¥½å•Šï¼Œæˆ‘å“‹å¯ä»¥è½‰åŽ»å¦ä¸€å€‹è©±é¡Œã€‚'
];

const politeOpeners = [
  'å¤šè¬åˆ†äº«ï¼',
  'æ˜Žç™½å–‡ï¼',
  'å¥½å˜¢ï¼',
  'æ­£å•Šï¼'
];

// Cache synthesized TTS by text to avoid repeat calls; keep it small.
const ttsCache = new Map();
const MAX_TTS_CACHE = 50;

async function generateAIResponse(userText, scenario, history) {
  console.log('ðŸ¤– generateAIResponse called with:', { userText: userText.substring(0, 20), scenario, hasApiKey: !!hkbuApiKey });
  
  if (!hkbuApiKey) {
    console.warn('âš ï¸ HKBU API key not configured, using mock');
    return mockAiReply(userText, scenario);
  }
  
  try {
    const systemMessage = `ä½ ä¿‚ä¸€å€‹å‹å–„å˜…å»£æ±è©±è€å¸«ã€‚ä½ å˜…å·¥ä½œä¿‚å¹«å­¸ç”Ÿç·´ç¿’å»£æ±è©±å°è©±ã€‚
å ´æ™¯ï¼š${scenario || 'æ—¥å¸¸å°è©±'}

æŒ‡å¼•ï¼š
1. ç”¨åœ°é“å»£æ±è©±å›žæ‡‰
2. èªžæ°£è‡ªç„¶è¦ªåˆ‡
3. å¦‚æžœå­¸ç”Ÿæœ‰æ–‡æ³•æˆ–ç”¨è©žéŒ¯èª¤ï¼Œæº«æŸ”åœ°ç³¾æ­£
4. é¼“å‹µå­¸ç”Ÿç¹¼çºŒç·´ç¿’
5. å›žæ‡‰é•·åº¦ä¿æŒ 1-3 å¥ï¼Œå””å¥½å¤ªé•·
6. ç”¨ç¹é«”ä¸­æ–‡æ›¸å¯«`;

    const messages = [
      { role: 'system', content: systemMessage },
      ...history.slice(-6).map(h => ({ 
        role: h.role === 'user' ? 'user' : 'assistant', 
        content: h.text 
      })),
      { role: 'user', content: userText }
    ];

    const url = `${hkbuBaseUrl}/deployments/${hkbuModel}/chat/completions?api-version=${hkbuApiVersion}`;
    console.log('ðŸ“¡ Calling HKBU API:', url);
    
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'accept': 'application/json',
        'Content-Type': 'application/json',
        'api-key': hkbuApiKey,
      },
      body: JSON.stringify({
        messages: messages,
        temperature: 1.0,
        max_tokens: 150,
        stream: false
      })
    });

    console.log('ðŸ“¥ HKBU API response status:', response.status, response.statusText);
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error('âŒ HKBU API error response:', errorText);
      throw new Error(`LLM API failed: ${response.status} ${response.statusText} - ${errorText}`);
    }

    const data = await response.json();
    console.log('ðŸ“¦ HKBU API response data:', JSON.stringify(data).substring(0, 200));
    
    const aiResponse = data.choices?.[0]?.message?.content || '';
    
    if (aiResponse) {
      console.log('âœ… LLM Response generated:', aiResponse.substring(0, 50));
      return aiResponse.trim();
    }
    
    throw new Error('No content in LLM response');
  } catch (err) {
    console.error('âŒ LLM API error:', err.message);
    console.log('âš ï¸ Falling back to mock response');
    return mockAiReply(userText, scenario);
  }
}

function mockAiReply(userText, scenario) {
  const opener = politeOpeners[Math.floor(Math.random() * politeOpeners.length)];
  const seed = promptSeeds[Math.floor(Math.random() * promptSeeds.length)];
  const scenarioHint = scenario ? `ï¼ˆæƒ…æ™¯ï¼š${scenario}ï¼‰` : '';
  const echo = userText ? `ä½ å•±å•±è¬›ï¼šã€Œ${userText}ã€` : 'ä½ å¯ä»¥å…ˆè¬›è¬›ä½ æƒ³ç·´ç¿’å˜…å…§å®¹ã€‚';
  return `${opener} ${echo} ${scenarioHint} ${seed}`.trim();
}

function generateMockTtsDataUri() {
  // Minimal valid WAV file (silent audio)
  return 'data:audio/wav;base64,UklGRiQAAABXQVZFZm10IBAAAAABAAEAQB8AAEAfAAABAAgAZGF0YQAAAAA=';
}

app.get('/api/health', (_req, res) => {
  res.json({
    status: 'ok',
    timestamp: Date.now(),
    version: appVersion,
    ttsProvider: ttsProvider === 'azure' ? 'azure' : 'mock'
  });
});

app.get('/api/scenarios', (_req, res) => {
  res.json({ scenarios });
});

app.post('/api/session', (_req, res) => {
  const sessionId = uuidv4();
  conversations.set(sessionId, []);
  res.json({ sessionId });
});

// Speech-to-Text endpoint (Azure ASR for Cantonese)
app.post('/api/speech-to-text', async (req, res) => {
  const { audioData } = req.body;
  
  if (!audioData) {
    return res.status(400).json({ error: 'Missing audioData' });
  }

  const ttsProvider = process.env.TTS_PROVIDER || 'mock';
  
  if (ttsProvider === 'azure') {
    try {
      const speechKey = process.env.AZURE_SPEECH_KEY;
      const speechRegion = process.env.AZURE_SPEECH_REGION || 'eastasia';
      
      if (!speechKey) {
        throw new Error('AZURE_SPEECH_KEY not configured');
      }

      // Convert base64 to buffer
      const audioBuffer = Buffer.from(audioData.replace(/^data:audio\/\w+;base64,/, ''), 'base64');

      const response = await fetch(
        `https://${speechRegion}.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=zh-HK`,
        {
          method: 'POST',
          headers: {
            'Ocp-Apim-Subscription-Key': speechKey,
            'Content-Type': 'audio/wav; codec=audio/pcm; samplerate=16000',
          },
          body: audioBuffer,
        }
      );

      if (!response.ok) {
        const errorBody = await response.text();
        console.error('Azure ASR error response:', errorBody);
        throw new Error(`Azure ASR failed: ${response.status} ${response.statusText} - ${errorBody}`);
      }

      const result = await response.json();
      
      return res.json({
        transcript: result.DisplayText || '',
        confidence: result.RecognitionStatus === 'Success' ? 0.9 : 0.5,
        provider: 'azure',
      });
    } catch (err) {
      console.error('Azure ASR error:', err.message);
      // Fallback to mock
      return res.json({
        transcript: '(æ¨¡æ“¬) ä½ å¥½ï¼Œæˆ‘æƒ³ç·´ç¿’å»£æ±è©±',
        confidence: 0.8,
        provider: 'mock',
        error: err.message,
      });
    }
  }

  // Mock ASR fallback
  res.json({
    transcript: '(æ¨¡æ“¬) ä½ å¥½ï¼Œæˆ‘æƒ³ç·´ç¿’å»£æ±è©±',
    confidence: 0.8,
    provider: 'mock',
  });
});

app.post('/api/recognize-and-respond', async (req, res) => {
  const { sessionId, userText = '', scenario = '' } = req.body || {};
  if (!sessionId) {
    return res.status(400).json({ error: 'sessionId is required' });
  }

  // Basic payload hygiene
  const trimmedUserText = typeof userText === 'string' ? userText.slice(0, 400).trim() : '';
  const scenarioText = typeof scenario === 'string' ? scenario.slice(0, 120) : '';

  if (!conversations.has(sessionId)) {
    conversations.set(sessionId, []);
  }

  let history = conversations.get(sessionId);
  
  // Generate AI response using real LLM
  const aiText = await generateAIResponse(trimmedUserText, scenarioText, history);
  
  // Generate intelligent feedback using LLM
  let feedback = '';
  if (trimmedUserText && hkbuApiKey) {
    try {
      const feedbackPrompt = `åˆ†æžä»¥ä¸‹å»£æ±è©±å¥å­å˜…ç™¼éŸ³åŒæ–‡æ³•ï¼Œæä¾›ç°¡çŸ­å»ºè­°ï¼ˆ1å¥è©±ï¼‰ï¼šã€Œ${trimmedUserText}ã€`;
      feedback = await generateAIResponse(feedbackPrompt, 'ç™¼éŸ³åˆ†æž', []);
      feedback = `ï¼ˆåˆ†æžï¼‰${feedback}`;
    } catch (err) {
      feedback = 'ï¼ˆåˆ†æžï¼‰ç¹¼çºŒç·´ç¿’ï¼Œä½ åšå¾—å¥½å¥½ï¼';
    }
  } else {
    feedback = trimmedUserText ? 'ï¼ˆåˆ†æžï¼‰ç¹¼çºŒç·´ç¿’ï¼Œä½ åšå¾—å¥½å¥½ï¼' : 'è«‹è©¦ä¸‹è¬›ä¸€å¥ä½ æƒ³ç·´ç¿’å˜…å¥å­ã€‚';
  }

  history.push({ role: 'user', text: trimmedUserText, timestamp: Date.now() });
  history.push({ role: 'ai', text: aiText, timestamp: Date.now() });
  if (history.length > 20) history = history.slice(-20);
  conversations.set(sessionId, history);

  // TTS Synthesis
  let ttsAudio = null;
  let ttsError = null;
  let ttsFallback = false;
  const ttsStartTime = Date.now();
  
  if (ttsProvider === 'azure' && azureTtsKey) {
    try {
      const cacheKey = aiText.trim().toLowerCase();
      if (ttsCache.has(cacheKey)) {
        ttsAudio = ttsCache.get(cacheKey);
        console.log('âœ“ TTS cache hit');
      } else {
        console.log('Synthesizing Azure TTS for:', aiText.substring(0, 30) + '...');
        ttsAudio = await synthesizeAzure(aiText);
        if (ttsAudio) {
          console.log('âœ“ TTS synthesized, length:', ttsAudio.length);
          ttsCache.set(cacheKey, ttsAudio);
          if (ttsCache.size > 50) {
            const firstKey = ttsCache.keys().next().value;
            ttsCache.delete(firstKey);
          }
        } else {
          console.warn('âš  TTS synthesis returned null');
        }
      }
    } catch (err) {
      console.error('âœ— Azure TTS failed:', err.message);
      ttsError = err.message;
      ttsFallback = true;
    }
  } else {
    console.log('TTS provider not configured, using mock');
  }
  
  if (!ttsAudio) {
    console.log('Generating mock TTS audio');
    ttsAudio = generateMockTtsDataUri();
    if (!ttsFallback) ttsFallback = true;
  }
  
  const ttsLatency = Date.now() - ttsStartTime;
  const totalLatency = Date.now() - (req.startTime || Date.now());

  console.log('Sending response:', {
    aiTextLength: aiText.length,
    ttsAudioLength: ttsAudio ? ttsAudio.length : 0,
    ttsProvider: ttsAudio && !ttsFallback ? 'azure' : 'mock',
    latencyMs: totalLatency
  });

  res.json({ 
    aiText, 
    feedback, 
    ttsAudio, 
    history,
    latencyMs: totalLatency,
    ttsProvider: ttsAudio && !ttsFallback ? 'azure' : 'mock',
    ttsLatency,
    ttsError,
    ttsFallback
  });
});

// Centralized error guard
// eslint-disable-next-line no-unused-vars
app.use((err, _req, res, _next) => {
  console.error(err);
  res.status(500).json({ error: 'internal_error', message: 'Server error, please try again.' });
});

async function synthesizeAzure(text) {
  if (!azureTtsKey || !azureTtsRegion) throw new Error('Azure TTS key/region missing');
  
  // Escape XML special characters
  const escapedText = text
    .replace(/&/g, '&amp;')
    .replace(/</g, '&lt;')
    .replace(/>/g, '&gt;')
    .replace(/"/g, '&quot;')
    .replace(/'/g, '&apos;');
  
  const ssml = `<?xml version="1.0" encoding="utf-8"?>
<speak version="1.0" xml:lang="zh-HK">
  <voice name="${azureVoice}">
    <prosody rate="${azureRate}" pitch="${azurePitch}">${escapedText}</prosody>
  </voice>
</speak>`;
  const ttsEndpoint = `https://${azureTtsRegion}.tts.speech.microsoft.com/cognitiveservices/v1`;

  const controller = new AbortController();
  const timeout = setTimeout(() => controller.abort(), 10000);

  try {
    const ttsRes = await fetch(ttsEndpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/ssml+xml',
        'X-Microsoft-OutputFormat': 'audio-16khz-128kbitrate-mono-mp3',
        'Ocp-Apim-Subscription-Key': azureTtsKey
      },
      body: ssml,
      signal: controller.signal
    });
    clearTimeout(timeout);
    
    if (!ttsRes.ok) {
      const errorBody = await ttsRes.text();
      console.error('Azure TTS error response:', errorBody);
      throw new Error(`Azure TTS error ${ttsRes.status}: ${errorBody}`);
    }
    
    const buffer = Buffer.from(await ttsRes.arrayBuffer());
    return `data:audio/mpeg;base64,${buffer.toString('base64')}`;
  } catch (err) {
    clearTimeout(timeout);
    throw err;
  }
}

export async function handler(req, res) {
  // not used in this runtime
}

app.listen(port, () => {
  console.log(`Backend listening on port ${port}`);
  console.log(`Allowing origin: ${clientOrigin}`);
  console.log(`TTS Provider: ${ttsProvider}`);
  console.log(`HKBU API configured: ${hkbuApiKey ? 'YES âœ“' : 'NO âœ—'}`);
  if (hkbuApiKey) {
    console.log(`HKBU Model: ${hkbuModel}`);
    console.log(`HKBU Base URL: ${hkbuBaseUrl}`);
  }
});
